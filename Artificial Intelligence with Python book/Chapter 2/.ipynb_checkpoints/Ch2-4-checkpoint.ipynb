{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding optimal training parameters using grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are working with classifiers, you do not always know what the best parameters are. You cannot brute-force it by checking for all possible combinations manually. This is where grid search becomes useful. Grid search allows us to specify a range of values and the classifier will automatically run various configurations to figure out the best combination of parameters. Let's see how to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.model_selection import GridSearchCV # Grid Search\n",
    "from sklearn.ensemble import ExtraTreesClassifier \n",
    "from sklearn.model_selection import train_test_split # Cross Validation\n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "def visualize_classifier(classifier, X, y, title=''):\n",
    "    # Define the minimum and maximum values for X and Y\n",
    "    # that will be used in the mesh grid\n",
    "    min_x, max_x = X[:, 0].min() - 1.0, X[:, 0].max() + 1.0\n",
    "    min_y, max_y = X[:, 1].min() - 1.0, X[:, 1].max() + 1.0\n",
    "\n",
    "    # Define the step size to use in plotting the mesh grid \n",
    "    mesh_step_size = 0.01\n",
    "\n",
    "    # Define the mesh grid of X and Y values\n",
    "    x_vals, y_vals = np.meshgrid(np.arange(min_x, max_x, mesh_step_size), np.arange(min_y, max_y, mesh_step_size))\n",
    "\n",
    "    # Run the classifier on the mesh grid\n",
    "    output = classifier.predict(np.c_[x_vals.ravel(), y_vals.ravel()])\n",
    "\n",
    "    # Reshape the output array\n",
    "    output = output.reshape(x_vals.shape)\n",
    "\n",
    "    # Create a plot\n",
    "    plt.figure()\n",
    "\n",
    "    # Specify the title\n",
    "    plt.title(title)\n",
    "\n",
    "    # Choose a color scheme for the plot \n",
    "    plt.pcolormesh(x_vals, y_vals, output, cmap=plt.cm.gray)\n",
    "\n",
    "    # Overlay the training points on the plot \n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=75, edgecolors='black', linewidth=1, cmap=plt.cm.Paired)\n",
    "\n",
    "    # Specify the boundaries of the plot\n",
    "    plt.xlim(x_vals.min(), x_vals.max())\n",
    "    plt.ylim(y_vals.min(), y_vals.max())\n",
    "\n",
    "    # Specify the ticks on the X and Y axes\n",
    "    plt.xticks((np.arange(int(X[:, 0].min() - 1), int(X[:, 0].max() + 1), 1.0)))\n",
    "    plt.yticks((np.arange(int(X[:, 1].min() - 1), int(X[:, 1].max() + 1), 1.0)))\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load input data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'data_random_forests.txt' \n",
    "data = np.loadtxt(input_file, delimiter=',') \n",
    "X, y = data[:, :-1], data[:, -1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the data into three classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate input data into three classes based on labels \n",
    "class_0 = np.array(X[y==0]) \n",
    "class_1 = np.array(X[y==1]) \n",
    "class_2 = np.array(X[y==2]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing datasets  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the grid of parameters that you want the classifier to test. Usually we keep one parameter constant and vary the other parameter. We then do it vice versa to figure out the best combination. In this case, we want to find the best values for n_estimators and max_depth. Let's specify the parameter grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid  \n",
    "parameter_grid = [ {'n_estimators': [100], 'max_depth': [2, 4, 7, 12, 16]}, \n",
    "                         {'max_depth': [4], 'n_estimators': [25, 50, 100, 250]} \n",
    "                         ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the metrics that the classifier should use to find the best combination of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['precision_weighted', 'recall_weighted'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each metric, we need to run the grid search, where we train the classifier for a particular combination of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Searching optimal parameters for precision_weighted\n",
      "\n",
      "##### Searching optimal parameters for recall_weighted\n"
     ]
    }
   ],
   "source": [
    "for metric in metrics: \n",
    "    print(\"\\n##### Searching optimal parameters for\", metric) \n",
    "\n",
    "    classifier = GridSearchCV( ExtraTreesClassifier(random_state=0),\n",
    "                              parameter_grid, cv=5, scoring=metric) \n",
    "    \n",
    "    classifier.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the best score for each parameter combination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters: {'max_depth': 4, 'n_estimators': 25}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBest parameters:\", classifier.best_params_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the performance report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.84      0.88        79\n",
      "         1.0       0.85      0.86      0.85        70\n",
      "         2.0       0.84      0.92      0.88        76\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       225\n",
      "   macro avg       0.87      0.87      0.87       225\n",
      "weighted avg       0.87      0.87      0.87       225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test) \n",
    "print(\"\\nPerformance report:\\n\") \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
