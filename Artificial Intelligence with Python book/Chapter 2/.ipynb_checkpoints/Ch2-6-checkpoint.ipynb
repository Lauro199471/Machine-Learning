{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting traffic using Extremely Random Forest regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply the concepts we learned in the previous sections to a real world problem. We will be using the dataset available at: https://archive.ics.uci.edu/ml/datasets/Dodgers+Loop+Sensor . This dataset consists of data that counts the number of vehicles passing by on the road during baseball games played at Los Angeles Dodgers stadium. In order to make the data readily available for analysis, we need to pre-process it. The pre-processed data is in the file traffic_data.txt. In this file, each line contains comma-separated strings. Let's take the first line as an example:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Tuesday,00:00,San Francisco,no,3__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Day of the week, time of the day, opponent team, binary value indicating whether or not a baseball game is currently going on (yes/no), number of vehicles passing by.\n",
    "\n",
    "__Our goal is to predict the number of vehicles going by using the given information.__ Since the output variable is continuous valued, we need to build a regressor that can predict the output. We will be using Extremely Random Forests to build this regressor. Let's go ahead and see how to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import classification_report, mean_absolute_error \n",
    "from sklearn import preprocessing \n",
    "from sklearn.ensemble import ExtraTreesRegressor \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split # Cross Validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data in the file traffic_data.txt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:\n",
      " [['Tuesday' '00:00' 'San Francisco' 'no' '3']\n",
      " ['Tuesday' '00:05' 'San Francisco' 'no' '8']\n",
      " ['Tuesday' '00:10' 'San Francisco' 'no' '10']\n",
      " ['Tuesday' '00:15' 'San Francisco' 'no' '6']\n",
      " ['Tuesday' '00:20' 'San Francisco' 'no' '1']]\n"
     ]
    }
   ],
   "source": [
    "# Load input data \n",
    "input_file = 'traffic_data.txt' \n",
    "data = [] \n",
    "with open(input_file, 'r') as f: \n",
    "      for line in f.readlines(): \n",
    "            items = line[:-1].split(',') \n",
    "            data.append(items) \n",
    "\n",
    "data = np.array(data) \n",
    "print(\"Data:\\n\" , data[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to encode the non-numerical features in the data. We also need to ensure that we don't encode numerical features. Each feature that needs to be encoded needs to have a separate label encoder. We need to keep track of these encoders because we will need them when we want to compute the output for an unknown data point. Let's create those label encoders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      " [[ 5  0 13  0]\n",
      " [ 5  1 13  0]\n",
      " [ 5  2 13  0]\n",
      " [ 5  3 13  0]\n",
      " [ 5  4 13  0]]\n",
      "\n",
      "y:\n",
      " [ 3  8 10  6  1]\n"
     ]
    }
   ],
   "source": [
    "# Convert string data to numerical data \n",
    "label_encoder = []  \n",
    "X_encoded = np.empty(data.shape) \n",
    "for i, item in enumerate(data[0]): \n",
    "    if item.isdigit(): \n",
    "        X_encoded[:, i] = data[:, i] \n",
    "    else: \n",
    "        label_encoder.append(preprocessing.LabelEncoder()) \n",
    "        X_encoded[:, i] = label_encoder[-1].fit_transform(data[:, i]) \n",
    "\n",
    "X = X_encoded[:, :-1].astype(int) \n",
    "y = X_encoded[:, -1].astype(int) \n",
    "print(\"X:\\n\" , X[0:5])\n",
    "print(\"\\ny:\\n\" , y[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing datasets  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train an extremely Random Forests regressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=4,\n",
       "          max_features='auto', max_leaf_nodes=None,\n",
       "          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "          min_samples_leaf=1, min_samples_split=2,\n",
       "          min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "          oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extremely Random Forests regressor \n",
    "params = {'n_estimators': 100, 'max_depth': 4, 'random_state': 0} \n",
    "regressor = ExtraTreesRegressor(**params) \n",
    "regressor.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the performance of the regressor on testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 7.42\n"
     ]
    }
   ],
   "source": [
    "# Compute the regressor performance on test data \n",
    "y_pred = regressor.predict(X_test) \n",
    "print(\"Mean absolute error:\", round(mean_absolute_error(y_test, y_pred), 2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how to compute the output for an unknown data point. We will be using those label encoders to convert non-numerical features into numerical values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing encoding on single data instance\n",
    "test_datapoint = ['Saturday', '10:20', 'Atlanta', 'no']\n",
    "test_datapoint_encoded = [-1] * len(test_datapoint)\n",
    "count = 0\n",
    "\n",
    "for i, item in enumerate(test_datapoint):\n",
    "    if item.isdigit():\n",
    "        test_datapoint_encoded[i] = int(test_datapoint[i])\n",
    "    else:\n",
    "        test_datapoint_encoded[i] = int(label_encoder[i].transform([test_datapoint[i]]))\n",
    "        count = count + 1 \n",
    "\n",
    "test_datapoint_encoded = np.array(test_datapoint_encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted traffic: 26\n"
     ]
    }
   ],
   "source": [
    "# Predict the output for the test datapoint \n",
    "print(\"Predicted traffic:\", int(regressor.predict([test_datapoint_encoded])[0])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you will get 26 as the output, which is pretty close to the actual value. You can confirm this from the data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape:\n",
      " (17568, 5)\n",
      "['Saturday' '09:40' 'Atlanta' 'no' '26']\n",
      "['Saturday' '10:05' 'Atlanta' 'no' '26']\n",
      "['Saturday' '10:10' 'Atlanta' 'no' '26']\n",
      "['Saturday' '10:30' 'Atlanta' 'no' '26']\n",
      "['Saturday' '11:10' 'Atlanta' 'no' '26']\n",
      "['Saturday' '11:25' 'Atlanta' 'no' '26']\n",
      "['Saturday' '12:30' 'Atlanta' 'no' '26']\n",
      "['Saturday' '15:00' 'Atlanta' 'no' '26']\n",
      "['Saturday' '18:40' 'Atlanta' 'no' '26']\n",
      "['Saturday' '19:40' 'Atlanta' 'yes' '26']\n",
      "['Saturday' '20:30' 'Atlanta' 'yes' '26']\n",
      "['Saturday' '23:25' 'Atlanta' 'no' '26']\n"
     ]
    }
   ],
   "source": [
    "input_file = 'traffic_data.txt' \n",
    "data = [] \n",
    "with open(input_file, 'r') as f: \n",
    "      for line in f.readlines(): \n",
    "            items = line[:-1].split(',') \n",
    "            data.append(items) \n",
    "\n",
    "data = np.array(data) \n",
    "print(\"Data Shape:\\n\" , np.shape(data))\n",
    "\n",
    "num_of_Sampels = len(data)\n",
    "rows=0\n",
    "\n",
    "for x in range(num_of_Sampels):\n",
    "    if(data[x,-1] == '26' and data[x,0] == 'Saturday' and data[x,2] == 'Atlanta'):\n",
    "        print(data[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
