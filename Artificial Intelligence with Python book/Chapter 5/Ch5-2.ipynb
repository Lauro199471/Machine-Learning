{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking objects using colorspaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information obtained by frame differencing is useful, but we will not be able to build a robust tracker with it. It is very sensitive to noise and it does not really track an object completely. To build a robust object tracker, we need to know what characteristics of the object can be used to track it accurately. This is where color spaces become relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An image can be represented using various color spaces. The RGB color space is probably the most popular color space, but it does not lend itself nicely to applications like object tracking. So we will be using the HSV color space instead. It is an intuitive color space model that is closer to how humans perceive color."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert the captured frame from RGB to HSV colorspace, and then use color thresholding to track any given object. We should note that we need to know the color distribution of the object so that we can select the appropriate ranges for thresholding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to grab the current frame from the webcam. Start by reading it from the video capture object:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get the current frame from the webcam \n",
    "def get_frame(cap, scaling_factor): \n",
    "    # Read the current frame from the video capture object \n",
    "    _, frame = cap.read() \n",
    "    \n",
    "    # Resize the image \n",
    "    frame = cv2.resize(frame, None, fx=scaling_factor,  \n",
    "            fy=scaling_factor, interpolation=cv2.INTER_AREA) \n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the video capture object \n",
    "cam = cv2.VideoCapture(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the scaling factor to be used to resize the captured frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scaling factor for the images \n",
    "scaling_factor = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate indefinitely until the user hits the Esc key. Grab the current frame to start:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep reading the frames from the webcam  \n",
    "# until the user hits the 'Esc' key \n",
    "while True: \n",
    "    # Grab the current frame \n",
    "    frame = get_frame(cam, scaling_factor)  \n",
    "    \n",
    "    # Convert the image to HSV colorspace \n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) \n",
    "    \n",
    "    # Define the approximate HSV color range for the color of human skin:\n",
    "    # Define range of skin color in HSV \n",
    "    lower = np.array([0, 70, 60]) \n",
    "    upper = np.array([50, 150, 255]) \n",
    "    \n",
    "    blue_lower=np.array([100,150,0],np.uint8)\n",
    "    blue_upper=np.array([140,255,255],np.uint8)\n",
    "    # Threshold the HSV image to get only skin color \n",
    "    mask = cv2.inRange(hsv, blue_lower, blue_upper) \n",
    "\n",
    "    # Bitwise-AND between the mask and original image \n",
    "    img_bitwise_and = cv2.bitwise_and(frame, frame, mask=mask) \n",
    "\n",
    "    # Run median blurring to smoothen the image\n",
    "    img_median_blurred = cv2.medianBlur(img_bitwise_and, 5) \n",
    "\n",
    "    # Display the input and output \n",
    "    cv2.imshow('Raw', frame) \n",
    "    cv2.imshow('Filter', img_median_blurred) \n",
    "\n",
    "    # Check if the user hit the 'Esc' key \n",
    "    c = cv2.waitKey(5)  \n",
    "    if c == 27: \n",
    "        break \n",
    "        \n",
    "# Close all the windows \n",
    "cv2.destroyAllWindows() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
