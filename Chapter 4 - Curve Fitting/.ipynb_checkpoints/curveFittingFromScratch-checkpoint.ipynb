{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size: (366, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002732</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005464</td>\n",
       "      <td>-4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008197</td>\n",
       "      <td>-6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010929</td>\n",
       "      <td>-9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.013661</td>\n",
       "      <td>-9.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time  temp\n",
       "0  0.002732   0.1\n",
       "1  0.005464  -4.5\n",
       "2  0.008197  -6.3\n",
       "3  0.010929  -9.6\n",
       "4  0.013661  -9.9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('temp.csv');\n",
    "print(\"data size:\" , data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time(5 samples): \n",
      " [[0.00273224]\n",
      " [0.00546448]\n",
      " [0.00819672]\n",
      " [0.01092896]\n",
      " [0.0136612 ]]\n",
      "\n",
      "temp(5 samples): \n",
      " [[ 0.1]\n",
      " [-4.5]\n",
      " [-6.3]\n",
      " [-9.6]\n",
      " [-9.9]]\n"
     ]
    }
   ],
   "source": [
    "time = data.iloc[:,0:1].values\n",
    "temp = data.iloc[:,1:2].values\n",
    "print(\"time(5 samples): \\n\" , time[0:5])\n",
    "print(\"\\ntemp(5 samples): \\n\" , temp[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = time \n",
    "y = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a Test and random Train Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(X, y):\n",
    "    \"\"\" Random shuffle of the samples in X and y \"\"\"\n",
    "    idx = np.arange(X.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y , test_size_ratio = 50):\n",
    "    '''\n",
    "        Split the training data from test data in the ratio specified in\n",
    "        test_size \n",
    "    '''\n",
    "    nSamples = len(y);\n",
    "    test_size_ratio = test_size_ratio / 100.0;\n",
    "    testSample = int(test_size_ratio * nSamples);\n",
    "    split_i = nSamples - testSample;\n",
    "    \n",
    "    \"\"\" Split the data into train and test sets \"\"\"\n",
    "    X, y = shuffle_data(X, y)\n",
    "    \n",
    "    X_train, X_test = X[:split_i], X[split_i:]\n",
    "    y_train, y_test = y[:split_i], y[split_i:]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (220, 1)\n",
      "X_test:   (146, 1)\n",
      "\n",
      "\n",
      "y_train:  (220, 1)\n",
      "y_test:   (146, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size_ratio = 40) # 40% total Samples\n",
    "print(\"X_train: \" , X_train.shape)\n",
    "print(\"X_test:  \"  , X_test.shape)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"y_train: \" , y_train.shape)\n",
    "print(\"y_test:  \"  , y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "_,nFeatures = data.shape; \n",
    "poly_degree = nFeatures;\n",
    "print(poly_degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation\n",
    "    allows us to compare different machine learning methods and get a sense of how well they will work in pratice\n",
    "1. TRAIN the machine learning method\n",
    "2. TEST the machine learning methods\n",
    "    \n",
    "    A terrible approach would be to use all of the data to estimate the parameters(train the algorithm) because then there wouldnt be any data to test the method. We need to know how the parameters perform.\n",
    "    \n",
    "ideally you want :\n",
    "\n",
    "75% of data for TRAINING\n",
    "\n",
    "25% of data for TESTING\n",
    "\n",
    "10 Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation_sets(X, y, k_folds):\n",
    "    \"\"\" Split the data into k sets of training / test data \"\"\"\n",
    "    X, y = shuffle_data(X, y)\n",
    "    n_samples = len(y)\n",
    "    left_overs = {}\n",
    "    n_left_overs = (n_samples % k_folds)\n",
    "\n",
    "    if n_left_overs != 0: # If not evenly divided get the last few samples\n",
    "        left_overs[\"X\"] = X[-n_left_overs:] # Get last nleftover rows\n",
    "        left_overs[\"y\"] = y[-n_left_overs:]\n",
    "        X = X[:-n_left_overs] # X[0 ~ nleftover]\n",
    "        y = y[:-n_left_overs]\n",
    "\n",
    "    X_split = np.split(X, k_folds) # numOfFOlds by (numSamples / numFolds)\n",
    "    y_split = np.split(y, k_folds)\n",
    "    sets = []\n",
    "    for i in range(k_folds):\n",
    "        X_test, y_test = X_split[i], y_split[i]\n",
    "        X_train = np.concatenate(X_split[:i] + X_split[i + 1:], axis=0)\n",
    "        y_train = np.concatenate(y_split[:i] + y_split[i + 1:], axis=0)\n",
    "        sets.append([X_train, X_test, y_train, y_test])\n",
    "\n",
    "    # Add left over samples to last set as training samples\n",
    "    if n_left_overs != 0:\n",
    "        np.append(sets[-1][0], left_overs[\"X\"], axis=0)\n",
    "        np.append(sets[-1][2], left_overs[\"y\"], axis=0)\n",
    "\n",
    "    return np.array(sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train total:  (324, 1)\n",
      "X_test total:   (36, 1)\n",
      "Y_train total:  (324, 1)\n",
      "Y_test total:   (36, 1)\n"
     ]
    }
   ],
   "source": [
    "k_folds = 10;\n",
    "# cross_validation_sets = [X_train, X_test, y_train, y_test]\n",
    "cross_validation_sets = k_fold_cross_validation_sets(X, y, k_folds); \n",
    "print(\"X_train total: \" ,cross_validation_sets[0,0].shape);\n",
    "print(\"X_test total:  \" ,cross_validation_sets[0,1].shape);\n",
    "print(\"Y_train total: \" ,cross_validation_sets[0,2].shape);\n",
    "print(\"Y_test total:  \" ,cross_validation_sets[0,3].shape);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Ridge Regression\n",
    "Performs a non-linear transformation of the data before fitting the model\n",
    "and doing predictions which allows for doing non-linear regression.\n",
    "sarameters\n",
    "    -----------\n",
    "    degree: int\n",
    "        The degree of the polynomial that the independent variable X will be transformed to.\n",
    "    n_iterations: float\n",
    "        The number of training iterations the algorithm will tune the weights for.\n",
    "    learning_rate: float\n",
    "        The step length that will be used when updating the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding regularization constant using cross validation:\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_error = float(\"inf\");\n",
    "best_reg_factor = None;\n",
    "print (\"Finding regularization constant using cross validation:\")\n",
    "k_folds = 10;\n",
    "for reg_factor in np.arange(0, 1,1):\n",
    "    cross_validation_sets = k_fold_cross_validation_sets(X, y, k_folds); # [X_train, X_test, y_train, y_test]\n",
    "    # print(cross_validation_sets[0,0].shape) # X_train total\n",
    "    # print(cross_validation_sets[0,1].shape) # X_test total\n",
    "    mse = 0;\n",
    "    for _X_train, _X_test, _y_train, _y_test in cross_validation_sets:\n",
    "        model = PolynomialRidgeRegression(degree=poly_degree, \n",
    "                                    reg_factor=reg_factor,\n",
    "                                    learning_rate=0.001,\n",
    "                                    n_iterations=10000)\n",
    "        model.fit(_X_train, _y_train)\n",
    "        y_pred = model.predict(_X_test)\n",
    "        _mse = mean_squared_error(_y_test, y_pred)\n",
    "        mse += _mse\n",
    "    mse /= k"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
